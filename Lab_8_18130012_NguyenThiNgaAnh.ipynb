{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhanThyAn/Lab-2_MayHoc/blob/main/Lab_8_20130195_PhanThiAn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab deals with **GridSearchCV** for tuning the hyper-parameters of an estimator and applying vectorization techniques to the **movie reviews dataset** for classification task. \n",
        "\n",
        "*   **Deadline: 23:59, 17/4/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn import datasets\n",
        "from sklearn import metrics \n",
        "import seaborn as sns\n",
        "from prettytable import PrettyTable\n",
        "from numpy import set_printoptions\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB,ComplementNB\n",
        "from numpy import average\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.datasets import load_iris\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import scipy.cluster.hierarchy as shc\n",
        "from scipy.stats import mode\n",
        "from nltk.metrics.scores import accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. With **iris** dataset\n",
        "*  1.1. Apply **GridSearchCV** for **SVM** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x_dG9SA5OhGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#code\n",
        "dataset = datasets.load_iris()\n",
        "X = dataset.data\n",
        "y= dataset.target\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "rf_svm = svm.SVC()\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "grid_rf_svm = GridSearchCV(estimator=rf_svm, param_grid=param_grid, scoring='accuracy', n_jobs=5, cv = 10, refit=True, return_train_score=True)\n",
        "grid_rf_svm.fit(X_train, y_train)\n",
        "y_predict= grid_rf_svm.predict(X_test)\n",
        "acc_svm=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_svm=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_svm= metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_svm=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_rf_svm.best_params_)\n",
        "print(acc_svm,pre_svm, recall_svm, f1_svm)\n",
        "SVM =['SVM', round(acc_svm, 2), round(pre_svm, 2), round(recall_svm, 2), round(f1_svm, 2)]"
      ],
      "metadata": {
        "id": "62jExOZ952fF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8cedf6-44e0-4a0b-bed1-b2b3da394fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
            "1.0 1.0 1.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.2. Apply **GridSearchCV** for **kNN** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "```\n",
        "where\n",
        "\n",
        "    *  **n_neighbors**: Decide the best k based on the values we have computed earlier.\n",
        "    *  **weights**: Check whether adding weights to the data points is beneficial to the model or not. 'uniform' assigns no weight, while 'distance' weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points.\n",
        "    *  **metric**: The distance metric to be used will calculating the similarity.\n"
      ],
      "metadata": {
        "id": "2g--8cng53sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "knn_class= KNeighborsClassifier()\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "grid_knn_class = GridSearchCV(estimator=knn_class, param_grid=grid_params, scoring='accuracy', n_jobs=6, cv = 10, refit=True, return_train_score=True)\n",
        "grid_knn_class.fit(X_train, y_train)\n",
        "y_predict= grid_knn_class.predict(X_test)\n",
        "acc_knn=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_knn=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_knn=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_knn=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_knn_class.best_params_)\n",
        "print(acc_knn,pre_knn, recall_knn, f1_knn)\n",
        "KNN =['KNN', round(acc_knn, 2), round(pre_knn, 2), round(recall_knn, 2), round(f1_knn, 2)]"
      ],
      "metadata": {
        "id": "fX0_kItYPism",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "982fc773-f29d-4daa-936d-eab7984dfbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "0.9555555555555556 0.9558404558404558 0.9558404558404558 0.9558404558404558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  1.3. Apply **GridSearchCV** for **Random Forest** to find the best hyperparameters using the following param_grid.\n",
        "\n",
        "```\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "3lQSOcjL_TIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "rf_class= RandomForestClassifier()\n",
        "grid_rf_class = GridSearchCV(estimator=rf_class, param_grid=param_grid, scoring='accuracy', n_jobs=4, cv = 10, refit=True, return_train_score=True)\n",
        "grid_rf_class.fit(X_train, y_train)\n",
        "y_predict= grid_rf_class.predict(X_test)\n",
        "acc_rf=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_rf=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_rf=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_rf=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_rf_class.best_params_)\n",
        "print(acc_rf,pre_rf, recall_rf, f1_rf)\n",
        "RF =['RandomForest', round(acc_rf, 2), round(pre_rf, 2), round(recall_rf, 2), round(f1_rf, 2)]"
      ],
      "metadata": {
        "id": "OlyF9WpN_01p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb71f8a-51e3-4619-b7cb-8133cf970c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 6, 'max_features': 'log2', 'max_leaf_nodes': 3, 'n_estimators': 25}\n",
            "0.9555555555555556 0.9558404558404558 0.9558404558404558 0.9558404558404558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   1.4 Compare the best obtained results from 1.1 to 1.3 (use PrettyTable to dispaly the results)"
      ],
      "metadata": {
        "id": "G3N7TD7s_3Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = PrettyTable(['Classfication', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row(SVM)\n",
        "t.add_row(KNN)\n",
        "t.add_row(RF)\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl4QAI4jpoxM",
        "outputId": "e7581733-8080-4c1f-bd3e-2c46e0027c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "| Classfication | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   1.0    |    1.0    |  1.0   | 1.0  |\n",
            "|      KNN      |   0.96   |    0.96   |  0.96  | 0.96 |\n",
            "|  RandomForest |   0.96   |    0.96   |  0.96  | 0.96 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   Apply **GridSearchCV** to different classification algorithms such as **SVM, kNN, LogisticRegression, RandomForest**.\n",
        "*   Compare the results obtained by the best hyperparameters among classification algorithms."
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.1. Apply **GridSearchCV** to **SVM** \n"
      ],
      "metadata": {
        "id": "pnoVB8J4vV36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X = cancer.data\n",
        "y= cancer.target\n",
        "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "rf_svm = svm.SVC()\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf','linear']}\n",
        "grid_rf_svm = GridSearchCV(estimator=rf_svm, param_grid=param_grid, scoring='accuracy', n_jobs=5, cv = 10, refit=True, return_train_score=True)\n",
        "grid_rf_svm.fit(X_train, y_train)\n",
        "y_predict= grid_rf_svm.predict(X_test)\n",
        "acc_svm=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_svm=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_svm= metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_svm=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_rf_svm.best_params_)\n",
        "print(acc_svm,pre_svm, recall_svm, f1_svm)\n",
        "SVM2 =['SVM2', round(acc_svm, 2), round(pre_svm, 2), round(recall_svm, 2), round(f1_svm, 2)]"
      ],
      "metadata": {
        "id": "-ZTSvsJdvYqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55cee33f-6535-496e-adc2-3d895463b8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
            "0.9415204678362573 0.9433262711864407 0.9305555555555556 0.9362891207153502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.2. Apply **GridSearchCV** to **kNN** "
      ],
      "metadata": {
        "id": "ol1U_T_NvcqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "knn_class= KNeighborsClassifier()\n",
        "grid_params = { 'n_neighbors' : [5,7,9,11,13,15],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean','manhattan']}\n",
        "grid_knn_class = GridSearchCV(estimator=knn_class, param_grid=grid_params, scoring='accuracy', n_jobs=6, cv = 10, refit=True, return_train_score=True)\n",
        "grid_knn_class.fit(X_train, y_train)\n",
        "y_predict= grid_knn_class.predict(X_test)\n",
        "acc_knn=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_knn=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_knn=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_knn=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_knn_class.best_params_)\n",
        "print(acc_knn,pre_knn, recall_knn, f1_knn)\n",
        "KNN2 =['KNN2', round(acc_knn, 2), round(pre_knn, 2), round(recall_knn, 2), round(f1_knn, 2)]"
      ],
      "metadata": {
        "id": "kt71yrAoBwYE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef2a2ad-1b2d-4d01-9e29-581b6b897704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metric': 'manhattan', 'n_neighbors': 13, 'weights': 'uniform'}\n",
            "0.935672514619883 0.9387397009459872 0.9226190476190477 0.9296585767174002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.3. Apply **GridSearchCV** to **LogisticRegression** "
      ],
      "metadata": {
        "id": "pPkAvse-BxNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
        "    'multi_class':['auto', 'ovr', 'multinomial'],\n",
        "    'solver':['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
        "}\n",
        "lr_class= LogisticRegression()\n",
        "grid_lr_class = GridSearchCV(estimator=lr_class, param_grid=param_grid, scoring='accuracy', n_jobs=4, cv = 10, refit=True, return_train_score=True)\n",
        "grid_lr_class.fit(X_train, y_train)\n",
        "y_predict= grid_lr_class.predict(X_test)\n",
        "acc_lr=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_lr=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_lr=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_lr=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_lr_class.best_params_)\n",
        "print(acc_lr,pre_lr, recall_lr, f1_lr)\n",
        "LR =['Logistic Regression', round(acc_lr, 2), round(pre_lr, 2), round(recall_lr, 2), round(f1_lr, 2)]"
      ],
      "metadata": {
        "id": "nyYjpHFbB1Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.4. Apply **GridSearchCV** to **RandomForest** "
      ],
      "metadata": {
        "id": "3NjSLo5jB1xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'max_leaf_nodes': [3, 6, 9],\n",
        "}\n",
        "rf_class= RandomForestClassifier()\n",
        "grid_rf_class = GridSearchCV(estimator=rf_class, param_grid=param_grid, scoring='accuracy', n_jobs=4, cv = 10, refit=True, return_train_score=True)\n",
        "grid_rf_class.fit(X_train, y_train)\n",
        "y_predict= grid_rf_class.predict(X_test)\n",
        "acc_rf=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_rf=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_rf=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_rf=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_rf_class.best_params_)\n",
        "print(acc_rf,pre_rf, recall_rf, f1_rf)\n",
        "RF2 =['RandomForest2', round(acc_rf, 2), round(pre_rf, 2), round(recall_rf, 2), round(f1_rf, 2)]"
      ],
      "metadata": {
        "id": "nktGtM0PB7XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fce1bc7-f447-4e6c-9407-c688e12ac75c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 3, 'max_features': 'log2', 'max_leaf_nodes': 9, 'n_estimators': 25}\n",
            "0.9473684210526315 0.9448061556673573 0.9417989417989417 0.9432626728110599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   2.5. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "NZJ3BSHpB9Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "t = PrettyTable(['Classfication', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row(SVM2)\n",
        "t.add_row(KNN2)\n",
        "t.add_row(LR)\n",
        "t.add_row(RF2)\n",
        "print(t)\n"
      ],
      "metadata": {
        "id": "8LS_IYfNCFEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61b5c44-11d8-45c8-9d00-dfaa3fff0788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+----------+-----------+--------+------+\n",
            "|    Classfication    | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------------+----------+-----------+--------+------+\n",
            "|         SVM2        |   0.94   |    0.94   |  0.93  | 0.94 |\n",
            "|         KNN2        |   0.94   |    0.94   |  0.92  | 0.93 |\n",
            "| Logistic Regression |   0.96   |    0.95   |  0.96  | 0.96 |\n",
            "|    RandomForest2    |   0.95   |    0.94   |  0.94  | 0.94 |\n",
            "+---------------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "The dataset consists of **2000 user-created movie reviews** archived on the IMDb(Internet Movie Database). The reviews are equally partitioned into a positive set and a negative set (1000+1000). Each review consists of a plain text file (.txt) and a class label representing the overall user opinion. \n",
        "The class attribute has only two values: **pos** (positive) or **neg** (negative).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.1 Importing additional libraries"
      ],
      "metadata": {
        "id": "lDcxOQRmDz_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk, random\n",
        "nltk.download('movie_reviews')#download movie reviews dataset\n",
        "from nltk.corpus import movie_reviews\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjyW06skDwvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dbcc92-6f11-4788-e34d-44b1ba4fd98b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.2. Movie reviews information"
      ],
      "metadata": {
        "id": "RJpsTIiyv-1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "print(len(movie_reviews.fileids()))\n",
        "print(movie_reviews.categories())\n",
        "print(movie_reviews.words()[:100])\n",
        "print(movie_reviews.fileids()[:10])"
      ],
      "metadata": {
        "id": "5ZE7A0Au1Pg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4152d6-3c38-41d5-efda-53cd8aca734f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['neg', 'pos']\n",
            "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]\n",
            "['neg/cv000_29416.txt', 'neg/cv001_19502.txt', 'neg/cv002_17424.txt', 'neg/cv003_12683.txt', 'neg/cv004_12641.txt', 'neg/cv005_29357.txt', 'neg/cv006_17022.txt', 'neg/cv007_4992.txt', 'neg/cv008_29326.txt', 'neg/cv009_29417.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.3. Create dataset from movie reviews"
      ],
      "metadata": {
        "id": "6pHmMpqMHS23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]\n",
        "random.seed(123)\n",
        "random.shuffle(documents)"
      ],
      "metadata": {
        "id": "45aY6woMHSH5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Reviews/Documents: {}'.format(len(documents)))\n",
        "print('Corpus Size (words): {}'.format(np.sum([len(d) for (d,l) in documents])))\n",
        "print('Sample Text of Doc 1:')\n",
        "print('-'*30)\n",
        "print(' '.join(documents[0][0][:50])) # first 50 words of the first document"
      ],
      "metadata": {
        "id": "NNke0Da5HqFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a359e8-0ff7-4fb7-f956-f2703f5205ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Reviews/Documents: 2000\n",
            "Corpus Size (words): 1583820\n",
            "Sample Text of Doc 1:\n",
            "------------------------------\n",
            "most movies seem to release a third movie just so it can be called a trilogy . rocky iii seems to kind of fit in that category , but manages to be slightly unique . the rocky formula of \" rocky loses fight / rocky trains / rocky wins fight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_distr = Counter([label for (words, label) in documents])\n",
        "print(sentiment_distr)"
      ],
      "metadata": {
        "id": "vVFUEhnXHsGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5535ed8-e4f2-4ee9-c033-550285e04738"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'pos': 1000, 'neg': 1000})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.4. Train test split"
      ],
      "metadata": {
        "id": "jTXiEbMzHgVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(documents, test_size = 0.33, random_state=42)"
      ],
      "metadata": {
        "id": "v_-0gZZFHvJN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Sentiment Distrubtion for Train and Test\n",
        "print(Counter([label for (words, label) in train]))\n",
        "print(Counter([label for (words, label) in test]))"
      ],
      "metadata": {
        "id": "UUGlm5TGHvpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f16a741-e84d-4ce6-97fa-c6497bfa1e1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'neg': 674, 'pos': 666})\n",
            "Counter({'pos': 334, 'neg': 326})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [' '.join(words) for (words, label) in train]\n",
        "X_test = [' '.join(words) for (words, label) in test]\n",
        "y_train = [label for (words, label) in train]\n",
        "y_test = [label for (words, label) in test]"
      ],
      "metadata": {
        "id": "l1ppl_0RHx1P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.5. Text Vectorization"
      ],
      "metadata": {
        "id": "7xUaXrjxH6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "tfidf_vec = TfidfVectorizer(min_df = 10, token_pattern = r'[a-zA-Z]+')\n",
        "X_train_bow = tfidf_vec.fit_transform(X_train) # fit train\n",
        "X_test_bow = tfidf_vec.transform(X_test) # transform test"
      ],
      "metadata": {
        "id": "fzwM0nsIH-8l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.6. Apply **SVM** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "BP1vB3loIF28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "rf_svm = svm.SVC()\n",
        "param_grid3 = {'C': [1, 10],\n",
        "              'gamma': [1, 0.1],\n",
        "              'kernel': ['rbf','linear']}\n",
        "grid_rf_svm = GridSearchCV(estimator=rf_svm, param_grid=param_grid3, scoring='accuracy', n_jobs=5, cv = 10, refit=True, return_train_score=True)\n",
        "grid_rf_svm.fit(X_train_bow, y_train)\n",
        "y_predict= grid_rf_svm.predict(X_test_bow)\n",
        "acc_svm=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_svm=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_svm= metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_svm=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_rf_svm.best_params_)\n",
        "print(acc_svm,pre_svm, recall_svm, f1_svm)\n",
        "SVM3 =['SVM3', round(acc_svm, 2), round(pre_svm, 2), round(recall_svm, 2), round(f1_svm, 2)]"
      ],
      "metadata": {
        "id": "b3FHQqh1Hlrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bef0f8b-790c-4899-d66a-9dbf57e67080"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
            "0.8121212121212121 0.8122242647058824 0.8119833951728446 0.8120366372380594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.7. Apply **RandomForest** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "N1Fy8jYBIdxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid3 = {\n",
        "    'n_estimators': [25, 100],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth': [ 6, 9],\n",
        "    'max_leaf_nodes': [3, 6]\n",
        "}\n",
        "rf_class= RandomForestClassifier()\n",
        "grid_rf_class = GridSearchCV(estimator=rf_class, param_grid=param_grid3, scoring='accuracy', n_jobs=4, cv = 10, refit=True, return_train_score=True)\n",
        "grid_rf_class.fit(X_train_bow, y_train)\n",
        "y_predict= grid_rf_class.predict(X_test_bow)\n",
        "acc_rf=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_rf=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_rf=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_rf=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_rf_class.best_params_)\n",
        "print(acc_rf,pre_rf, recall_rf, f1_rf)\n",
        "RF3 =['RandomForest3', round(acc_rf, 2), round(pre_rf, 2), round(recall_rf, 2), round(f1_rf, 2)]"
      ],
      "metadata": {
        "id": "Fyfw2R-gIhWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2162fd06-069d-46de-c9a8-4a858bb20423"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'max_depth': 6, 'max_features': 'sqrt', 'max_leaf_nodes': 6, 'n_estimators': 100}\n",
            "0.7575757575757576 0.7577826022961436 0.7573564527386943 0.7573953078047032\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.8. Apply **kNN** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "_btsVKjIIiLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "knn_class= KNeighborsClassifier()\n",
        "grid_params3 = { 'n_neighbors' : [5,7,9],\n",
        "               'weights' : ['uniform','distance'],\n",
        "               'metric' : ['minkowski','euclidean']}\n",
        "grid_knn_class = GridSearchCV(estimator=knn_class, param_grid=grid_params3, scoring='accuracy', n_jobs=6, cv = 10, refit=True, return_train_score=True)\n",
        "grid_knn_class.fit(X_train_bow, y_train)\n",
        "y_predict= grid_knn_class.predict(X_test_bow)\n",
        "acc_knn=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_knn=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_knn=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_knn=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_knn_class.best_params_)\n",
        "print(acc_knn,pre_knn, recall_knn, f1_knn)\n",
        "KNN3 =['KNN3', round(acc_knn, 2), round(pre_knn, 2), round(recall_knn, 2), round(f1_knn, 2)]"
      ],
      "metadata": {
        "id": "IZmFu1ZQImhn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "df74bae9-9f1e-4afc-c1f1-4eb40ae4d0e7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-44246a163169>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                'metric' : ['minkowski','euclidean']}\n\u001b[1;32m      6\u001b[0m \u001b[0mgrid_knn_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mknn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_params3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgrid_knn_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mgrid_knn_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_bow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0macc_knn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    565\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.9. Apply **LogisticRegression** with **GridSearchCV** "
      ],
      "metadata": {
        "id": "0Ix_HeVGIvDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "param_grid4 = {\n",
        "    'multi_class':['auto', 'ovr'],\n",
        "    'solver':['lbfgs', 'liblinear', 'newton-cg']\n",
        "}\n",
        "lr_class= LogisticRegression()\n",
        "grid_lr_class = GridSearchCV(estimator=lr_class, param_grid=param_grid4, scoring='accuracy', n_jobs=4, cv = 10, refit=True, return_train_score=True)\n",
        "grid_lr_class.fit(X_train_bow, y_train)\n",
        "y_predict= grid_lr_class.predict(X_test_bow)\n",
        "acc_lr=metrics.accuracy_score(y_test, y_predict)\n",
        "pre_lr=metrics.precision_score(y_test, y_predict, average='macro')\n",
        "recall_lr=metrics.recall_score(y_test, y_predict, average='macro')\n",
        "f1_lr=metrics.f1_score(y_test, y_predict, average='macro')\n",
        "print(grid_lr_class.best_params_)\n",
        "print(acc_lr,pre_lr, recall_lr, f1_lr)\n",
        "LR3 =['Logistic Regression3', round(acc_lr, 2), round(pre_lr, 2), round(recall_lr, 2), round(f1_lr, 2)]"
      ],
      "metadata": {
        "id": "sTd3alCMIr-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5361b7b4-cec3-42e0-e6dc-041f58afbf01"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'multi_class': 'auto', 'solver': 'liblinear'}\n",
            "0.7954545454545454 0.7955809485286682 0.7952959112449947 0.7953488372093023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   3.10. Compare the best obtained results among classification algorithms (use PrettyTable to dispaly the results) "
      ],
      "metadata": {
        "id": "nhYF2y6eI058"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "t = PrettyTable(['Classfication', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row(SVM3)\n",
        "t.add_row(RF3)\n",
        "t.add_row(KNN3)\n",
        "t.add_row(LR3)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "B2bBArbu7HxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2fdf519-abe2-46ff-dee1-53b88d040dc8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------+----------+-----------+--------+------+\n",
            "|    Classfication     | Accuracy | Precision | Recall |  F1  |\n",
            "+----------------------+----------+-----------+--------+------+\n",
            "|         SVM3         |   0.81   |    0.81   |  0.81  | 0.81 |\n",
            "|    RandomForest3     |   0.76   |    0.76   |  0.76  | 0.76 |\n",
            "| Logistic Regression3 |   0.8    |    0.8    |  0.8   | 0.8  |\n",
            "+----------------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}